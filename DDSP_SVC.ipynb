{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Original project link：https://github.com/yxlllc/DDSP-SVC**"
      ],
      "metadata": {
        "id": "BucKkxL-GBYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is a fast training SVC project, very suitable for the free version, the training degree can be obtained within the limits of the model file, while inference on the quality of the input source is very low requirements. colab part of the code borrowed from Sovits' Colab."
      ],
      "metadata": {
        "id": "q1nt6Zl3GH2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process the data in advance.\n",
        "Require pure human voice, body whispering sound/gas sound is not suitable (difficult to extract F0), best to remove.\n",
        "When processing split into 2s-10s, maybe more than 20s is possible, this project is not eaten memory, but below 2s is not allowed.\n",
        "Remember to resample to 44.1kHz when processing, non-sampling rate can run but will greatly reduce the efficiency.\n",
        "Because of the free version of the limit, it is best to pre-process locally, and do not use non-44.1kHz data, the data quality in general, a limit of time can also get good training results."
      ],
      "metadata": {
        "id": "2_lQDUmDA-me"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset file structure.\n",
        "\n",
        "Place all the training set data (.wav format audio slices) in data/train/audio\n",
        "\n",
        "Put all the validation set data (.wav format audio slices) into data/val/audio\n",
        "\n",
        "Pack the data folder into a zip format named data.zip and upload it to the root of Google Cloud Drive\n",
        "\n",
        "It is recommended to pre-process locally to save time on the limit, and after pre-processing, just follow the same method as above to package and upload"
      ],
      "metadata": {
        "id": "7sdhuA_GaC9K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two training methods are provided, \"combsub-based model\" and \"sinusoidal additive synthesizer-based model (sin)\", the latter being less comprehensive than the former but still providing options."
      ],
      "metadata": {
        "id": "WL8x30ZODOZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modify the hyperparameters (such as \"bs\") to increase the video memory occupation may not improve efficiency (I tried to reduce anyway), the default parameter is about 4.85batch/s, almost no overfitting."
      ],
      "metadata": {
        "id": "Bl61DX8OENju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3/6 added the code of downloading the bottom mode, test convergence speed increased by about 40%, almost no tone leakage at 50k, the test is not very full, still can be a try."
      ],
      "metadata": {
        "id": "EBtSagh0UmUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3/8 updated multi-speaker training, the dataset structure is as follows, single person training can still use the previous dataset with no effect. The multi-speaker model can be enabled by modifying the 'n_spk' option in the configuration file.\n",
        "\n",
        "```\n",
        "# Training set\n",
        "# 1st speaker\n",
        "data/train/audio/1/aaa.wav\n",
        "data/train/audio/1/bbb.wav\n",
        "...\n",
        "# 2 speaker\n",
        "data/train/audio/2/ccc.wav\n",
        "data/train/audio/2/ddd.wav\n",
        "...\n",
        "\n",
        "# Validation set\n",
        "# 1st speaker\n",
        "data/val/audio/1/eee.wav\n",
        "data/val/audio/1/fff.wav\n",
        "...\n",
        "# 2nd speaker\n",
        "data/val/audio/2/ggg.wav\n",
        "data/val/audio/2/hhh.wav\n",
        "...\n",
        "```"
      ],
      "metadata": {
        "id": "OgATNlz5KKi9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SswdL0i0W8x",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Check GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVBUR74k0-tx",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Clone the github repository\n",
        "!git clone https://github.com/yxlllc/DDSP-SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDk-Clmv1L2w",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "%cd /content/DDSP-SVC\n",
        "!pip install pyworld praat-parselmouth torchcrepe einops local_attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSt6D7SS1WyW",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Download necessary files\n",
        "!wget -P pretrain/hubert/ https://github.com/bshall/hubert/releases/download/v0.1/hubert-soft-0d54a1f4.pt\n",
        "!wget -P pretrain/ https://github.com/openvpi/vocoders/releases/download/nsf-hifigan-v1/nsf_hifigan_20221211.zip\n",
        "!unzip -d /content/DDSP-SVC/pretrain /content/DDSP-SVC/pretrain/nsf_hifigan_20221211.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sFoApQR2YA_",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Loading Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlHZKit12fXc",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Get dataset from cloud disk\n",
        "!unzip -d / /content/drive/MyDrive/data.zip #自行修改路径与文件名"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBjSKnGQ2nf9"
      },
      "source": [
        "File structure:\n",
        "\n",
        "Put all training set data (audio slices in .wav format) into data/train/audio\n",
        "\n",
        "Put all validation set data (.wav format audio slices) into data/val/audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MoDzyro3u7E",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Data preprocessing, already processed can be skipped\n",
        "#@markdown ##Select training method\n",
        "way = \"combsub\" #@param [\"combsub\",\"sins\"]\n",
        "\n",
        "if way == \"combsub\":\n",
        "  !python preprocess.py -c configs/combsub.yaml\n",
        "if way == \"sins\":\n",
        "  !python preprocess.py -c configs/sins.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43HGp5n-4fgC",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Packing/Backing Up Datasets\n",
        "!zip -r dataset.zip /content/DDSP-SVC/data\n",
        "!cp /content/DDSP-SVC/dataset.zip /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0GVKPAS5dpO",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Set model backup\n",
        "#@markdown **Whether to back up the model to the cloud disk, colab explodes at any time, it is recommended to back up, and it is saved to the DDSP-SVC folder in the root directory of the cloud disk by default**\n",
        "Save_to_drive = True #@param {type:\"boolean\"}\n",
        "if Save_to_drive:\n",
        "  !rm -rf /content/DDSP-SVC/exp\n",
        "  !mkdir -p /content/drive/MyDrive/DDSPSVC\n",
        "  !ln -s /content/drive/MyDrive/DDSPSVC /content/DDSP-SVC/exp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download pre-trained model (optional)\n",
        "!wget -P exp https://github.com/yxlllc/DDSP-SVC/releases/download/1.0/opencpop.zip\n",
        "!mkdir /content/DDSP-SVC/exp/combsub-test/\n",
        "!mkdir /content/DDSP-SVC/exp/sin-test/\n",
        "!unzip -d /content/DDSP-SVC/exp /content/DDSP-SVC/exp/opencpop.zip\n",
        "!cp /content/DDSP-SVC/exp/opencpop/model_300000.pt /content/DDSP-SVC/exp/sin-test/\n",
        "!cp /content/DDSP-SVC/exp/opencpop/model_300000.pt /content/DDSP-SVC/exp/combsub-test/"
      ],
      "metadata": {
        "id": "k95eS0A7Snc-",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Before training, please open the \"/DDSP-SVC/config\" folder in the \"File\" tab on the left column, and modify the first \"combsub.yaml\" or \"sins.yaml\" (depending on your training method) On line 35, change \"cache_device: 'cpu'\" to \"cache_device: 'cuda'\", and click the \"File\" tab on the upper sidebar to save.**\n",
        "\n",
        "**This will further speed up training.**\n",
        "\n",
        "**Using the bottom model can properly increase the value of \"lr\" in line 39 in the early stage of training? (Without testing, you need to master it by yourself, don’t change it if you are not sure)**"
      ],
      "metadata": {
        "id": "sRhiVFhDE9GB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEbamAP96asx",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Start Training\n",
        "#@markdown ##Select training method\n",
        "way = \"combsub\" #@param [\"combsub\",\"sins\"]\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir exp\n",
        "\n",
        "%cd /content/DDSP-SVC\n",
        "if way == \"combsub\":\n",
        "  !python train.py -c configs/combsub.yaml\n",
        "if way == \"sins\":\n",
        "  !python train.py -c configs/sins.yaml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Reasoning (Multiple speakers modify the code to specify the speaker)\n",
        "#@markdown **Upload the processed \".wav\" input source file to the root directory of the cloud disk, and modify the following options**\n",
        "\n",
        "#@markdown **Select training method**\n",
        "way = \"combsub\" #@param [\"combsub\",\"sins\"]\n",
        "#@markdown **\".wav\" File filename**\n",
        "input = \"input\" #@param {type:\"string\"}\n",
        "input_path = \"/content/drive/MyDrive/\"\n",
        "input_name =  input_path + input\n",
        "model_path = \"/content/drive/MyDrive/DDSP-SVC\"\n",
        "#@markdown **Pitch adjustment**\n",
        "keychange = \"0\"  #@param {type:\"string\"}\n",
        "!python main.py -i {input_name}.wav -m {model_path}/{way}/model_best.pt -o {input_name}_result.wav -k {keychange} -e true"
      ],
      "metadata": {
        "id": "pMoC7hbBG7rx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}